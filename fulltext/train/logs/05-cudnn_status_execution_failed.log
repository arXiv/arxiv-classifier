Accelerator Optimized: 1 NVIDIA Tesla A100 GPU, 12 vCPUs, 85GB RAM
CUDNN_STATUS_EXECUTION_FAILED
.databunch(bs=16)



----------------------------
learn.fit_one_cycle(1, 1e-2)

0.00% [0/1 00:00<00:00]
epoch	train_loss	valid_loss	accuracy	time

 0.00% [0/4011 00:00<00:00]
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-8-3ea49add0339> in <module>
----> 1 learn.fit_one_cycle(1, 1e-2)

/opt/conda/lib/python3.7/site-packages/fastai/train.py in fit_one_cycle(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)
     21     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,
     22                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))
---> 23     learn.fit(cyc_len, max_lr, wd=wd, callbacks=callbacks)
     24 
     25 def fit_fc(learn:Learner, tot_epochs:int=1, lr:float=defaults.lr,  moms:Tuple[float,float]=(0.95,0.85), start_pct:float=0.72,

/opt/conda/lib/python3.7/site-packages/fastai/basic_train.py in fit(self, epochs, lr, wd, callbacks)
    198         else: self.opt.lr,self.opt.wd = lr,wd
    199         callbacks = [cb(self) for cb in self.callback_fns + listify(defaults.extra_callback_fns)] + listify(callbacks)
--> 200         fit(epochs, self, metrics=self.metrics, callbacks=self.callbacks+callbacks)
    201 
    202     def create_opt(self, lr:Floats, wd:Floats=0.)->None:

/opt/conda/lib/python3.7/site-packages/fastai/basic_train.py in fit(epochs, learn, callbacks, metrics)
     99             for xb,yb in progress_bar(learn.data.train_dl, parent=pbar):
    100                 xb, yb = cb_handler.on_batch_begin(xb, yb)
--> 101                 loss = loss_batch(learn.model, xb, yb, learn.loss_func, learn.opt, cb_handler)
    102                 if cb_handler.on_batch_end(loss): break
    103 

/opt/conda/lib/python3.7/site-packages/fastai/basic_train.py in loss_batch(model, xb, yb, loss_func, opt, cb_handler)
     24     if not is_listy(xb): xb = [xb]
     25     if not is_listy(yb): yb = [yb]
---> 26     out = model(*xb)
     27     out = cb_handler.on_loss_begin(out)
     28 

/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    530             result = self._slow_forward(*input, **kwargs)
    531         else:
--> 532             result = self.forward(*input, **kwargs)
    533         for hook in self._forward_hooks.values():
    534             hook_result = hook(self, input, result)

/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py in forward(self, input)
     98     def forward(self, input):
     99         for module in self:
--> 100             input = module(input)
    101         return input
    102 

/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    530             result = self._slow_forward(*input, **kwargs)
    531         else:
--> 532             result = self.forward(*input, **kwargs)
    533         for hook in self._forward_hooks.values():
    534             hook_result = hook(self, input, result)

/opt/conda/lib/python3.7/site-packages/fastai/text/learner.py in forward(self, input)
    263         raw_outputs,outputs,masks = [],[],[]
    264         for i in range(0, sl, self.bptt):
--> 265             r, o = self.module(input[:,i: min(i+self.bptt, sl)])
    266             if i>(sl-self.max_len):
    267                 masks.append(input[:,i: min(i+self.bptt, sl)] == self.pad_idx)

/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    530             result = self._slow_forward(*input, **kwargs)
    531         else:
--> 532             result = self.forward(*input, **kwargs)
    533         for hook in self._forward_hooks.values():
    534             hook_result = hook(self, input, result)

/opt/conda/lib/python3.7/site-packages/fastai/text/models/awd_lstm.py in forward(self, input, from_embeddings)
    119         new_hidden,raw_outputs,outputs = [],[],[]
    120         for l, (rnn,hid_dp) in enumerate(zip(self.rnns, self.hidden_dps)):
--> 121             raw_output, new_h = rnn(raw_output, self.hidden[l])
    122             new_hidden.append(new_h)
    123             raw_outputs.append(raw_output)

/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    530             result = self._slow_forward(*input, **kwargs)
    531         else:
--> 532             result = self.forward(*input, **kwargs)
    533         for hook in self._forward_hooks.values():
    534             hook_result = hook(self, input, result)

/opt/conda/lib/python3.7/site-packages/fastai/text/models/awd_lstm.py in forward(self, *args)
     52             #To avoid the warning that comes because the weights aren't flattened.
     53             warnings.simplefilter("ignore")
---> 54             return self.module.forward(*args)
     55 
     56     def reset(self):

/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py in forward(self, input, hx)
    557         if batch_sizes is None:
    558             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
--> 559                               self.dropout, self.training, self.bidirectional, self.batch_first)
    560         else:
    561             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,

RuntimeError: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED

